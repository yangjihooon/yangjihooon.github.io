---
layout: single
title: Dataflow
categories: 
    - AI accelerator
use_math: true
---

# <center> Dataflow </center>

## <center> 제 1 장 서론 </center>

Neural Networks (NNs)의 추론에서 발생하는 대부분의 연산들은 Multiplication and Accumulation (MAC) 연산이다. 예를 들어 Fully-Connected layer (FC layer)의 경우 Vector-Matrix Multiplication가 주된 연산이고 (Figure 01), Convolutional layer (CONV layer)의 경우 Convolution이 주된 연산이다 (Figure 02). Figure 01과 Figure 02를 보면, 각 연산은 결국 곱셈과 덧셈으로 구성된다. 즉, 여러 개의 MAC 연산들로 구성된다. MAC 연산은 세 종류의 데이터인 input feature map (IFMP), weight(WGT), partial sum(PSUM)을 필요로 한다. 연산에 사용되는 데이터의 종류도 세 가지이고, 실제 추론에서 이들 데이터는 크기가 크기 때문에, 메모리 접근 (memory access) 횟수가 많다. 메모리 접근은 에너지 소비가 크다. 또한, 세 종류의 데이터를 가져와야 하기 떄문에 메모리 병목 현상이 발생할 수 있다.

<p align="center"> <img src = "/assets/img/dataflow/f1.png"> </p>
<div align="center"> Figure 01 </div>
<br/>

<div align="center"> <img src="/assets/img/dataflow/f2.png"> </div>
<div align="center"> Figure 02 </div>
<br/>

메모리 병목 현상과 에너지 소비 문제를 고려하여 효과적으로 인공지능 추론을 가속하기 위해 사용되는 방법 중 하나는 데이터를 최대한 재사용하여 (data reuse) MAC 연산을 수행하는 것이다. 즉, 데이터 재사용을 최대화할 수 있는 데이터플로우를 (dataflow) 설계하는 것이다. 이때, 데이터를 재사용한다 함은 메모리 계층의 에너지 소모가 큰 계층에서 가져온 데이터를 에너지 소모가 작은 계층에 저장하여 사용함으로써 해당 데이터를 에너지 소모가 큰 계층에서 다시 가져오는 일을 줄이는 것을 말한다. MAC 연산과 관련하여 데이터의 재사용을 최대화하기 위해서는 한 번 가져온 데이터와 관련된 연산을 가능한 많이 수행해야 한다. 데이터플로우는 어떤 데이터를 어떤 방식으로 PE에 할당할 것인지, PE 사이에서는 어떤 데이터를 어떻게 이동시킬 것인지 등에 대한 것을 말한다. MAC 연산에는 세 가지 종류의 데이터가 존재하기 때문에 어떤 데이터를 어떻게 이동시킬지 등에 따라 여러 가지 데이터플로우가 존재할 수 있다.

<div align="center"> <img src="/assets/img/dataflow/f3.png"> </div>
<div align="center"> Figure 03 </div>
<br/>

<div align="center"> <img src="/assets/img/dataflow/f4.png"> </div>
<div align="center"> Figure 04 </div>
<br/>

<div align="center"> <img src="/assets/img/dataflow/f5.png"> </div>
<div align="center"> Figure 05 </div>
<br/>

여러 데이터플로우 중에서 컨볼루션 레이어를 효율적으로 처리하기 위한 대표적인 데이터플로우를 소개하고자 한다. 이해를 위해 그림을 통해 설명하고자 한다. Figure 03은 컨볼루션 레이어의 입력이 되는 input feature map (IFMP)이고, Figure 04는 filter 혹은 weight (WGT)이며, Figure 05는 컨볼루션 레이어의 출력인 output feature map (OFMP)이다.

## <center> 제 2장 Dataflow </center>

### 1. Weight Stationary (WS)

Weight Stationary (WS)는 WGT의 각 픽셀 혹은 값을 PE 내부 메모리에 저장하는 것을 말한다. 이때, stationary의 사전적 의미는 정지된, 변하지 않는이라는 뜻으로, 컨볼루션 레이어의 하나의 피연산자인 WGT가 고정되어 있다는 것을 의미한다. WGT 픽셀을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행하기 때문에, 여러 연산에서 WGT 픽셀을 재사용할 수 있다. 좀 더 자세히 말하자면, 에너지 소모가 큰 메모리 계층에 저장된 WGT를 에너지 소모가 작은 메모리 계층인 PE 내부 메모리에 저장하여, WGT가 PE 내부에 저장되어 있는 동안 해당 WGT와 관련된 가능한 많은 연산을 수행한다. 이에 따라 한번 가져온 WGT를 다시 가져오는 횟수가 줄어들게 된다. 즉, 에너지 소모가 큰 메모리 계층인 DRAM/GLB의 접근 횟수가 줄어들게 된다.

앞서 MAC 연산에는 세 가지 종류의 데이터가 필요하다고 하였다. WS에서 WGT가 기본적으로 PE 내부 메모리에 고정되어 있지만, 구체적으로 WGT의 어떤 픽셀을 어떤 순서로 고정시킬지, 그리고 IFMP와 PSUM은 어떤 방식으로 처리할 것인지에 따라 여러 데이터플로우가 가능하다. 즉, **WS를 기반으로 하는 데이터플로우는 여러가지가 존재한다.**

<div align="center"> <img src="/assets/img/dataflow/f6.png"> </div>
<div align="center"> Figure 06 </div>
<br/>

WS 기반의 데이터플로우의 한가지 예시는 Figure 06과 같다. 해당 데이터플로우에서 한 채널에 대한 각 WGT 픽셀은 PE array의 각 열에 해당하는 PE 내부에 저장되고, 한 채널에 대한 IFMP의 각 컨볼루션 윈도우의 (convolution window) 픽셀은 PE array에 스트리밍된다.

해당 데이터플로우의 동작은 다음과 같다.
- $t_{0}$ : col 1에 IFMP의 컨볼루션 윈도우 1개의 픽셀이 스트리밍되고, 각 PE는 곱셈을 수행한다. 이때, col 1은 weight 1이 관장하는 출력 채널의 한 OFMP 픽셀인 $P_{11}^{1}$의 PSUM 하나를 계산한다. 완전한 $P_{11}^{1}$은 WGT의 모든 채널에 대해 연산을 수행해야 하는데, 현재는 한 채널의 WGT 픽셀을 저장했기 때문에 $P_{11}^{1}$의 PSUM이 된다. 이에 따라 col 1 내의 각 PE는 $P_{11}^{1}$의 PSUM의 PSUM을 생성하게 된다.
- $t_{1}$ : col 2에 $t_{0}$의 컨볼루션 윈도우가 포워딩되고, col 1에 새로운 컨볼루션 윈도우 1개의 픽셀이 스트리밍되며, 각 PE는 곱셈을 수행합니다. col 2은 weight 2가 관장하는 출력 채널의 한 OFMP 픽셀인 $P_{11}^{2}$의 PSUM을 계산한다. col 1은 weight 1이 관장하는 출력 채널의 다른 OFMP 픽셀인 $P_{12}^{1}$의 PSUM을 계산한다. 또한, col 1 내의 각 PE는 $t_{0}$에서 계산한 $P_{11}^{1}$의 PSUM의 PSUM을 인접한 PE에 전달하면서 누적 연산을 수행한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩 된 IFMP의 컨볼루션 윈도우의 픽셀에 대해 곱셈하고, 이전 사이클에서 계산된 PSUM을 적절히 이동시키며 누적한다. 현재 Figure 06을 보면, PE array에 하나의 채널에 대한 WGT가 저장되어 있다. 따라서, 이와 관련된 모든 연산이 완료되면, 다른 채널에 대한 WGT가 PE 내부에 저장한 되고 이와 같은 채널의 IFMP의 컨볼루션 윈도우가 스트리밍되며 계산이 계속된다.

<div align="center"> <img src="/assets/img/dataflow/f7.png"> </div>
<div align="center"> Figure 07 </div>
<br/>

설계한 데이터플로우대로 데이터가 처리되는 양상은 알고리즘적으로 루프로 표현할 수 있는데, 이는 Figure 07과 같다. 배치 $N$에 대해 하나의 IFMP를 선택하여 WGT와 연산할 것이기 때문에 $N$ 루프가 가장 바깥에 위치한다. 한 채널의 WGT를 PE array에 저장하고, 이와 관련된 모든 연산이 완료되면 다른 채널의 WGT를 PE array에 저장할 것이기 때문에 $C_{i}$ 루프가 그 다음에 위치한다. 한편, Figure 03을 보면, PE array의 각 열은 한 순간에 서로 다른 출력 채널에 대한 OFMP 픽셀의 PSUM을 동시에 계산한다. 따라서, $C_{o}$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 열에 속한 각 PE는 해당 출력 채널의 OFMP 픽셀의 PSUM의 PSUM을 동시에 계산한다. 따라서, $H_{k}$, $W_{k}$ 루프 또한 병렬적으로 처리된다. 마지막으로, 매 사이클마다 IFMP의 컨볼루션 윈도우가 순차적으로 스트리밍되면서 연산되기 때문에 $H_{o}$, $W_{o}$ 루프가 제일 안쪽에 위치한다.

결과적으로 해당 데이터플로우는 컨볼루션 연산의 $C_{o}$, $H_{k}$, $W_{k}$ 차원을 PE array에 맵핑하고 (mapping), 이들 차원을 병렬적으로 계산한다. 이때, 특정 차원의 계산을 순차적으로 수행하는 것이 아닌 병렬적으로 수행하도록 데이터를 PE에 할당하는 것을 spatial unrolling이라고 한다. 즉, 해당 데이터플로우는 $C_{o}$, $H_{k}$, $W_{k}$ 차원의 계산을 spatial unrolling한다.

### 2. Output Stationary (OS)

Output Stationary (OS)는 PSUM을 PE 내부 메모리에 저장하는 것을 말한다. psum을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행되기 때문에, 여러 연산에서 PSUM을 재사용할 수 있다. 이에 따라 PSUM에 대한 DRAM/GLB의 접근 횟수가 줄어든다.

비교를 위해 앞선 WS를 다시 살펴보면, 각 PE에서 계산된 OFMP 픽셀의 PSUM의 PSUM은 매 사이클마다 인접한 PE 사이를 이동하며 누적되었다. 하지만, OS의 경우 PSUM이 PE 내부에 저장되어 있기 때문에, 매 사이클마다 계산된 PSUM은 PE 내부에서 누적될 것임을 예상할 수 있다. WS와 마찬가지로 OS 또한 데이터의 할당 방법에 따라 여러가지 데이터플로우가 존재한다. 

<div align="center"> <img src="/assets/img/dataflow/f8.png"> </div>
<div align="center"> Figure 08 </div>
<br/>

OS 기반의 데이터플로의 한가지 예시는 Figure 08과 같다. 각 WGT의 한 채널에 대한 픽셀과 IFMP의 한 채널에 대한 각 컨볼루션 윈도우의 픽셀을 PE에 스트리밍한다. 이후, 각 PE는 전달 받은 데이터에 대해 연산을 수행한 후 결과인 PSUM을 내부 메모리에 저장한다.

해당 데이터플로우의 동작을 관찰하면 다음과 같다.
- $t_{0}$ : PE0가 데이터를 곱셈한 후 이를 내부 메모리에 저장한다. 이때, PE0는 weight 1이 관장하는 출력 채널의 한 OFMP 픽셀인 $P_{11}^{1}$의 PSUM 하나를 계산하여, 내부 메모리에 저장한다.
- $t_{1}$ : PE2는 $P_{12}^{1}$의 PSUM 하나를 계산하여 내부 메모리에 저장한다. PE0은 새로운 $P_{11}^{1}$의 PSUM을 계산하여, $t_{0}$에서 계산한 $P_{11}^{1}$의 PSUM 누적시킨다. PE1은 $P_{11}^{2}$의 PSUM 하나를 계산한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩 된 IFMP의 컨볼루션 윈도우와 WGT에 대해 곱셈 연산을 하고, 이전 사이클에서 수행한 PSUM과 누적한다. 현재 Figure 08을 보면, PE array에 하나의 채널에 대한 IFMP의 컨볼루션 윈도우와 WGT가 스트리밍되고 있다. 따라서 이들 연산이 완료되면, 다른 채널에 대한 데이터가 스트리밍되며 계산이 계속된다.

<div align="center"> <img src="/assets/img/dataflow/f9.png"> </div>
<div align="center"> Figure 09 </div>
<br/>

이를 루프로 표현하면 Figure 09과 같다. 여러 IFMP 중 하나의 IFMP에 대해 연산을 수행하기 때문에, $N$ 루프가 가장 바깥에 위치한다. 이후, 한 채널의 IFMP와 WGT에 대해 연산을 수행하기 때문에, $C_{i}$ 루프가 그 다음에 위치한다. 한편 Figure 08을 보면, PE array의 각 열은 한 순간에 서로 다른 출력 채널에 대해 OFMP을 계산한다. 따라서, $C_{o}$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 열에 속한 각 PE는 OFMP의 각 픽셀을 병렬적으로 계산한다. 따라서, $H_{o}$, $W_{o}$ 루프 또한 병렬적으로 처리된다. 마지막으로, 매 사이클마다 WGT와 IFMP가 순차적으로 스트리밍되면서 연산되기 때문에 $H_{k}$, $W_{k}$ 루프가 제일 안쪽에 위치한다. 결과적으로 해당 데이터플로우는 컨볼루션 연산의 $C_{o}$, $H_{o}$, $W_{o}$ 차원을 spatial unrolling한다.

### 3. Input Stationary (IS)

Input Stationary (IS)는 IFMP의 각 픽셀을 PE 내부 메모리에 저장하는 것을 말한다. IFMP 픽셀을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행하기 때문에, 여러 연산에서  IFMP 픽셀을 재사용할 수 있다. 이에 따라 IFMP를 가져오기 위한 DRAM/GLB의 접근 횟수가 줄어든다. IS 또한 각 데이터의 할당 방법에 따라 여러 데이터플로우가 존재한다.

<div align="center"> <img src="/assets/img/dataflow/f10.png"> </div>
<div align="center"> Figure 10 </div>
<br/>

IS 기반의 데이터플로우의 한가지 예시는 Figure 10와 같다. IFMP의 한 채널에 대한 각 컨볼루션 윈도우의 픽셀을 PE array의 각 열에 저장한다. 이후, 각 WGT의 한 채널에 대한 픽셀을 스트리밍한다.

해당 데이터플로우의 동작은 다음과 같다.
- $t_0$ : col 1에 weight 1의 픽셀이 스트리밍되고, 각 PE는 곱셈을 수행한다. 이때, col 1은 weight 1이 관장하는 출력 채널의 한 OFMP 픽셀인 $P_{11}^{1}$의 PSUM 하나를 계산한다다. 이에 따라 col 1 내의 각 PE는 $P_{11}^{1}$의 PSUM의 PSUM을 계산합니다.
- $t_1$ : col 2에 weight 1의 픽셀이 포워딩되고, col 1에 weight 2의 픽셀이 스트리밍되며, 각 PE는 곱셈을 수행한다. col 2는 weight 1이 관장하는 출력 채널의 한 OFMP 픽셀인 $P_{12}^{1}$의 PSUM을 계산한다. col 1은 weight 2가 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{11}^{2}$의 PSUM을 계산한다. 또한, col 1 내의 각 PE는 $t_0$에서 계산한 $P_{11}^{1}$의 PSUM의 PSUM을 인접한 PE에 전달하면서 누적 연산한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩된 WGT 픽셀에 대해 곱셈 연산을 하고, 이전 사이클에서 계산된 PSUM을 적절히 이동 시키며 누적한다. 현재 Figure 10을 보면, PE array에 하나의 채널에 대한 IFMP의 컨볼루션 윈도우가 저장되어 있다. 따라서, 이와 관련된 모든 연산이 완료되면, 다른 채널에 대한 IFMP의 컨볼루션 윈도우를 PE 내부에 저장한 후 이와 같은 채널의 WGT를 스트리밍하며 계산을 이어 나간다.

<div align="center"> <img src="/assets/img/dataflow/f11.png"> </div>
<div align="center"> Figure 11 </div>
<br/>

이를 루프로 표현하면 Figure 11과 같다. 여러 IFMP 중 하나의 IFMP를 선택하여 WGT와 연산할 것이기 때문에 $N$ 루프가 가장 바깥에 위치한다. 선택한 IFMP에서 한 채널에 대한 컨볼루션 윈도우를 PE array에 저장하였고, 이와 관련된 연산이 모두 완료되면 다음 채널에 대한 컨볼루션 윈도우를 PE array에 저장할 것이기 때문에 $C_{i}$ 루프가 다음에 위치한다. 한편, Figure 10을 보면, PE array의 각 열은 한 순간에 서로 다른 채널에 대한 OFMP 픽셀의 PSUM을 동시에 계산한다. 따라서, $C_{o}$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 열에 속한 각 PE는 해당 OFMP 픽셀의 PSUM의 PSUM을 동시에 계산한다. 따라서, $H_k$, $W_k$ 루프 또한 병렬적으로 처리된다. 마지막으로 매 사이클마다 WGT가 순차적으로 스트리밍되면서 처리되기 $H_o$, $W_o$ 루프가 제일 안쪽에 위치한다. 결과적으로 해당 데이터플로우는 $C_o$, $H_k$, $W_k$ 차원을 spatial unrolling한다.