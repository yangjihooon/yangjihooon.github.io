---
layout: post
title: Dataflow
categories: AI accelerator
---

# <center> Dataflow</center>

## <center> 제 1 장 서론 </center>

Neural Networks (NNs)의 추론에서 발생하는 대부분의 연산들은 Multiplication and Accumulation (MAC) 연산이다. 예를 들어 Fully-Connected layer (FC layer)의 경우 Figure 01을 통해 알 수 있듯이 Vector-Matrix Multiplication이 주된 연산이다. 또한, Convolutional layer (CONV layer)의 경우 Figure 02에서 볼 수 있듯이 Convolution이 주된 연산이다. Figure 01과 Figure 02를 보면, 각 연산은 결국 곱셈과 덧셈으로 이뤄짐을 알 수 있다. 즉, 여러 개의 MAC 연산들로 구성된다. 이때, MAC 연산은 세 종류의 데이터인 input feature map (ifmp), weight (wgt), partial sum (psum)을 필요로 한다. 연산에 사용되는 데이터의 종류도 많고 실제 추론에서 이들 데이터는 크기가 크기 때문에, 메모리 접근 횟수가 많다. 메모리 접근은 에너지 소비가 크다. 또한, 세 종류의 데이터를 가져와야 하기 떄문에 메모리 병목 현상이 발생할 수 있다.

<div align="center">
    <img src="/assests/img/f1.png">
</div>

<div align="center">
    Figure 01
</div>
<br/>
<br/>

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f2.png">
</div>

<div align="center">
    Figure 02
</div>
<br/>
<br/>

메모리 병목 현상과 에너지 소비 문제를 고려하여 효과적으로 인공지능 추론을 가속하기 위해 사용되는 방법 중 하나는 데이터를 최대한 재사용하여 (data reuse) MAC 연산을 수행하는 것이다. 즉, data reuse를 최대화할 수 있는 dataflow를 설계하는 것이다. 이때, 데이터를 재사용한다 함은 메모리 계층의 에너지 소모가 큰 계층에서 가져온 데이터를 에너지 소모가 작은 계층에 저장하여 사용함으로써 해당 데이터를 에너지 소모가 큰 계층에서 다시 가져오는 일을 줄이는 것을 말한다. MAC 연산과 관련하여 데이터의 재사용을 최대화하기 위해서는 한 번 가져온 데이터와 관련된 연산을 가능한 많이 수행해야 한다. dataflow는 어떤 데이터를 어떤 방식으로 PE에 할당할 것인지, PE 사이에서는 어떤 데이터를 어떻게 이동시킬 것인지 등에 대한 것을 말한다. MAC 연산에는 세 가지 종류의 데이터가 존재하기 때문에 어떤 데이터를 어떻게 이동시킬지 등에 따라 여러 가지 dataflow가 존재할 수 있다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f3.png">
</div>

<div align="center">
    Figure 03
</div>
<br/>
<br/>

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f4.png">
</div>

<div align="center">
    Figure 04
</div>
<br/>
<br/>

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f5.png">
</div>

<div align="center">
    Figure 05
</div>
<br/>
<br/>

여러 dataflow 중에서 convolution layer를 효율적으로 처리하기 위한 대표적인 dataflow를 소개하고자 한다. Figure 03은 convolution layer의 입력이 되는 input feature map (ifmp)이고, Figure 04는 filter 혹은 weight (wgt)이며, Figure 05는 convolution layer의 출력인 output feature map (ofmp)이다.

## <center> 제 2장 Dataflow </center>

### 1. Weight Stationary

Weight Stationary는 (WS) wgt의 각 픽셀 혹은 값을 PE 내부 메모리에 저장하는 것을 말한다. wgt 픽셀을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행하기 때문에, 여러 연산에서 wgt 픽셀을 재사용할 수 있다. 이에 따라 wgt를 가져오기 (fetch) 위한 DRAM/GLB의 접근 횟수가 줄어든다.

앞서 MAC 연산에는 세 가지 종류의 데이터가 필요하다고 하였다. 이때, wgt가 기본적으로 PE 내부 메모리에 고정되어 있지만, 구체적으로 wgt의 어떤 픽셀을 어떤 순서로 고정시킬지, 그리고 ifmp와 psum은 어떤 방식으로 처리할 것인지에 따라 여러 dataflow가 가능하다. 즉, weight stationary를 기반으로 하는 dataflow는 여러가지가 존재할 수 있다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f6.png">
</div>

<div align="center">
    Figure 06
</div>
<br/>
<br/>

weight stationary 기반의 dataflow의 한가지 예시는 Figure 06과 같다. 해당 dataflow에서 한 채널에 대한 각 wgt 픽셀은 PE array의 각 column에 해당하는 PE 내부에 저장되고, 한 채널에 대한 ifmp의 각 convolution window의 픽셀은 PE array에 스트리밍된다.

해당 dataflow의 동작은 다음과 같다.
- $t_{0}$ : col 1에 ifmp의 convolution window 1개의 픽셀이 스트리밍되고, 각 PE는 곱셈을 수행한다. 이때, col 1은 weight 1이 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{11}^{1}$의 psum 하나를 계산한다. 완전한 $P_{11}^{1}$은 weight의 모든 채널에 대해 convolution 연산을 수행해야 하는데, 현재는 한 채널의 weight 픽셀을 저장했기 때문에 $P_{11}^{1}$의 psum이 된다. 이에 따라 col 1 내의 각 PE는 $P_{11}^{1}$의 psum의 psum을 생성하게 된다.
- $t_{1}$ : col 2에 $t_{0}$의 convolution window가 포워딩되고, col 1에 새로운 convolution window 1개의 픽셀이 스트리밍되며, 각 PE는 곱셈을 수행합니다. col 2은 weight 2가 관장하는 출력 채널의 한 ofmp pixel인 $P_{11}^{2}$의 psum을 계산한다. col 1은 weight 1이 관장하는 출력 채널의 다른 ofmp 픽셀인 $P_{12}^{1}$의 psum을 계산한다. 또한, col 1 내의 각 PE는 $t_{0}$에서 계산한 $P_{11}^{1}$의 psum의 psum을 인접한 PE에 전달하면서 누적 연산을 수행한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩 된 ifmp convolution window 픽셀에 대해 곱셈하고, 이전 사이클에서 계산된 psum을 적절히 이동시키며 누적한다. 현재 Figure 06을 보면, PE array에 하나의 채널에 대한 wgt가 저장되어 있다. 따라서, 이와 관련된 모든 연산이 완료되면, 다른 채널에 대한 wgt가 PE 내부에 저장한 되고 이와 같은 채널의 ifmp convolution window가 스트리밍되며 계산이 계속된다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f7.png">
</div>

<div align="center">
    Figure 07
</div>
<br/>
<br/>

설계한 dataflow대로 데이터가 처리되는 양상은 알고리즘적으로 루프로 표현할 수 있는데, 이는 Figure 07과 같다. 배치 N에 대해 하나의 ifmp를 선택하여 wgt와 연산할 것이기 때문에 $N$ 루프가 가장 바깥에 위치한다. 한 채널의 wgt를 PE array에 저장하고, 이와 관련된 모든 연산이 완료되면 다른 채널의 wgt를 PE array에 저장할 것이기 때문에 $C_{i}$ 루프가 그 다음에 위치한다. 한편, Figure 03을 보면, 각 column은 한 순간에 서로 다른 출력 채널에 대한 ofmp 픽셀의 psum을 동시에 계산한다. 따라서, $C_{o}$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 column에 속한 각 PE는 해당 출력 채널의 ofmp 픽셀의 psum의 psum을 동시에 계산한다. 따라서, $H_{k}$, $W_{k}$ 루프 또한 병렬적으로 처리된다. 마지막으로, 매 사이클마다 ifmp의 convolution window가 순차적으로 스트리밍되면서 연산되기 때문에 $H_{o}$, $W_{o}$ 루프가 제일 안쪽에 위치한다.

결과적으로 해당 dataflow는 convolution 연산의 $C_{o}$, $H_{k}$, $W_{k}$ 차원을 PE array에 mapping하고, 이들 차원을 병렬적으로 계산한다. 즉, $C_{o}$, $H_{k}$, $W_{k}$ 차원의 계산을 순차적으로 수행하는 것이 아닌 병렬적으로 수행하도록 데이터를 할당하는 것을 spatial unrolling이라고 한다.

### 2. Output Stationary (OS)

Output Stationary는 psum을 PE 내부 메모리에 저장하는 것을 말한다. psum을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행되기 때문에, 여러 연산에서 psum을 재사용할 수 있다. 이에 따라 psum을 가져오기 위한 DRAM/GLB의 접근 횟수가 줄어든다.

비교를 위해 앞선 weight stationary를 다시 살펴보면, 해당 dataflow에서 각 PE에서 계산된 ofmp 픽셀의 psum의 psum은 매 사이클마다 인접한 PE 사이를 이동하며 누적되었다. 하지만, output stationary의 경우 psum이 PE 내부에 저장되어 있기 때문에, 매 사이클마다 계산된 psum은 PE 내부에서 누적될 것임을 예상할 수 있다. output stationary 기반의 dataflow 또한 세 가지 데이터의 할당 방법에 따라 여러가지 dataflow가 존재한다. 

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f8.png">
</div>

<div align="center">
    Figure 08
</div>
<br/>
<br/>

output stationary 기반의 dataflow의 한가지 예시는 Figure 08과 같다. 각 wgt의 한 채널에 대한 픽셀과 ifmp의 한 채널에 대한 각 convolution window의 픽셀을 PE에 스트리밍한다. 이후, 각 PE는 전달 받은 데이터에 대해 연산을 수행한 후 결과인 psum을 내부 메모리에 저장한다.

해당 dataflow의 동작을 시간 순서대로 관찰하면 다음과 같다.
$t_{0}$ : PE0가 데이터를 곱셈한 후 이를 내부 메모리에 저장한다. 이때, PE0는 weight 1이 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{11}^{1}$의 psum 하나를 계산하여, 내부 메모리에 저장한다.
$t_{1}$ : PE2는 $P_{12}^{1}$의 psum 하나를 계산하여 내부 메모리에 저장한다. PE0은 새로운 $P_{11}^{1}$의 psum을 계산하여, $t_{0}$에서 계산한 $P_{11}^{1}$의 psum과 누적시킨다. PE1은 $P_{11}^{2}$의 psum 하나를 계산한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩 된 ifmp의 convolutional window와 wgt에 대해 곱셈 연산을 하고, 이전 사이클에서 수행한 psum과 누적한다. 현재 Figure 08을 보면, PE array에 하나의 채널에 대한 ifmp의 convolutional window와 wgt가 스트리밍되고 있다. 따라서 이들 연산이 완료되면, 다른 채널에 대한 데이터가 스트리밍되며 계산이 계속된다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f9.png">
</div>

<div align="center">
    Figure 09
</div>
<br/>
<br/>

이를 루프로 표현하면 Figure 09과 같다. 여러 ifmp 중 하나의 ifmp에 대해 연산을 수행하기 때문에, $N$ 루프가 가장 바깥에 위치한다. 이후, 한 채널의 ifmp와 wgt에 대해 연산을 수행하기 때문에, $C_{i}$ 루프가 그 다음에 위치한다. 한편 Figure 08을 보면, 각 column은 한 순간에 서로 다른 출력 채널에 대해 ofmp을 계산한다. 따라서, $C_{o}$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 column에 속한 각 PE는 ofmp의 각 픽셀을 병렬적으로 계산한다. 따라서, $H_{o}$, $W_{o}$ 루프 또한 병렬적으로 처리된다. 마지막으로, 매 사이클마다 wght와 ifmp가 순차적으로 스트리밍되면서 연산되기 때문에 $H_{k}$, $W_{k}$ 루프가 제일 안쪽에 위치한다. 결과적으로 해당 dataflow는 convolution 연산의 $C_{o}$, $H_{o}$, $W_{o}$ 차원을 spatial unrolling한다.

### 3. Input Stationary (IS)

Input Stationary는 ifmp의 각 픽셀을 PE 내부 메모리에 저장하는 것을 말한다. ifmp 픽셀을 한 번 PE 내부에 저장한 후 이와 관련된 가능한 많은 연산을 수행하기 때문에, 여러 연산에서  ifmp pixel을 재사용할 수 있다. 이에 따라 ifmp를 가져오기 위한 DRAM/GLB의 접근 횟수가 줄어든다. input stationary 또한 각 데이터의 할당 방법에 따라 여러 dataflow가 존재한다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f10.png">
</div>

<div align="center">
    Figure 10
</div>
<br/>
<br/>

input stationary 기반의 dataflow의 한가지 예시는 Figure 10>와 같다. ifmp의 한 채널에 대한 각 convolution window의 픽셀을 PE array의 각 column에 저장한다. 이후, 각 wgt의 한 채널에 대한 픽셀을 스트리밍한다.

해당 dataflow의 동작으 다음과 같다.
$t_0$ : col 1에 weight 1의 픽셀이 스트리밍되고, 각 PE는 곱셈을 수행한다. 이때, col 1은 weight 1이 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{11}^{1}$의 psum 하나를 계산한다다. 이에 따라 col 1 내의 각 PE는 $P_{11}^{1}$의 psum의 psum을 계산합니다.
$t_1$ : col 2에 weight 1의 픽셀이 포워딩되고, col 1에 weight 2의 픽셀이 스트리밍되며, 각 PE는 곱셈을 수행한다. col 2는 weight 1이 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{12}^{1}$의 psum을 계산한다. col 1은 weight 2가 관장하는 출력 채널의 한 ofmp 픽셀인 $P_{11}^{2}$의 psum을 계산한다. 또한, col 1 내의 각 PE는 $t_0$에서 계산한 $P_{11}^{1}$의 psum의 psum을 인접한 PE에 전달하면서 누적 연산한다.

위와 같이 매 사이클마다 PE array는 스트리밍 혹은 포워딩된 weight 픽셀에 대해 곱셈 연산을 하고, 이전 사이클에서 계산된 psum을 적절히 이동 시키며 누적한다. 현재 Figure 10을 보면, PE array에 하나의 채널에 대한 ifmp의 convolution window가 저장되어 있다. 따라서, 이와 관련된 모든 연산이 완료되면, 다른 채널에 대한 ifmp convolution window를 PE 내부에 저장한 후 이와 같은 채널의 weight를 스트리밍하며 계산을 이어 나간다.

<div align="center">
    <img src="\Users\home\OneDrive\df_posting/f11.png">
</div>

<div align="center">
    Figure 11
</div>
<br/>
<br/>

이를 루프로 표현하면 Figure 11과 같다. 여러 ifmp 중 하나의 ifmp를 선택하여 wgt와 연산할 것이기 때문에 $N$ 루프가 가장 바깥에 위치한다. 선택한 ifmp에서 한 채널에 대한 convolution window를 PE array에 저장하였고, 이와 관련된 연산이 모두 완료되면 다음 채널에 대한 convolution window를 PE array에 저장할 것이기 때문에 $C_i$ 루프가 다음에 위치한다. 한편, Figure 10을 보면, 각 column은 한 순간에 서로 다른 채널에 대한 ofmp 픽셀의 psum을 동시에 계산한다. 따라서, $C_o$ 루프가 다음에 위치하고 병렬적으로 처리된다. 또, 한 column에 속한 각 PE는 해당 ofmp 픽셀의 psum의 psum을 동시에 계산한다. 따라서, $H_k$, $W_k$$$$$ 루프 또한 병렬적으된처리됩니다. 마지막으로 매 사이클geight가 순차스트리밍ming되면서 처리되기 $H_o$, $W_o$, Wo 루프가 제일 안쪽한다 됩니다. 결과적으로 해당 datafl$C_o$, $H_k$, $W_k$ Wk, 차원을 spatial unrol한다.합니다.Hk, Wk, 차원을 spatial unrolling합니다.

