---
layout: single
title: Eyeriss
categories: 
  - paper review
  - AI accelerator
use_math: true
---

# <center> Eyeriss </center>

## <center> 제 1 장 서론 </center>

Convolutional Neural Network (CNN)  모델의 추론 과정은 높은 연산량 및 메모리 사용량을 보인다 . 최근 CNN 모델은 높은 정확도를 위해 크기가 커지고 있기에, 그 정도가 더 커지고 있다. 이에 따라 인공신경망 하드웨어 가속기는 모델의 추론을 위해 하이퍼파라미터  및 각종 데이터에 대한 오프칩 (off-chip)  메모리에 매우 빈번하게 접근한다. 하지만, 오프칩 메모리에 접근하는데 소모되는 에너지는 SRAM 버퍼와 같은 온칩 (on-chip) 메모리에 접근하거나 연산기가 소모하는 에너지 대비 상당히 높으므로, 기존의 가속기는 높은 에너지 소모량을 보인다. 따라서 Eyeriss 는 이러한 메모리 병목 및 에너지 사용량을 줄이기 위해 온칩 메모리에 가져온 데이터를 가속기 내에서 최대한 많이 재사용할 수 있도록 Row Stationary (RS) 데이터플로우를 제안하였으며, 이외에도 오프칩 메모리 대역폭 사용량을 줄이기 위해 RLE (Run Length Encoding) 기법을 통해 희소 데이터를 압축하여 오프칩 메모리에 저장하였다. 이후 문단에서는 Eyeriss의 데이터플로우에 대해 설명한다.

## <center> 제 2 장 Eyeriss 데이터플로우 </center>

### 1-D Convolution primitive in a PE

Eyeriss의 데이터플로우를 설명하기 위한 그림은 다음과 같다. Figure 01은 컨볼루션 레이어 (convolution ayer)의 입력인 input feature map (IFMP)이고, Figure 02는 해당 레이어의 filter 혹은 wegith (WGT)이며, Figure 03은 컨볼루션 레이어의 출력인 output feature map (OFMP)이다.

<p align="center"> <img src= "/assets/img/eyeriss/f1.png"> </p>
<div align="center"> Figure 01 </div>
<br/>

<p align="center"> <img src= "/assets/img/eyeriss/f2.png"> </p>
<div align="center"> Figure 02 </div>
<br/>

<p align="center"> <img src= "/assets/img/eyeriss/f3.png"> </p>
<div align="center"> Figure 03 </div>
<br/>

RS 데이터플로우를 설계하기 위한 첫 번째 단계로써 아이리스는 1차원 컨볼루션 프리미티브를 (1-D convolution promitive) 하나의 PE에 맵핑한다. 1차원 컨볼루션은 Figure 04과 같이 2개의 1차원 배열 형태의 데이터에 대해, 한 데이터가 오른쪽 방향으로 슬라이딩하며 컨볼루션 연산을 수행하는 것을 말한다. WGT 가 슬라이딩하며 IFMP와 연산을 수행하고, 그 결과 OFMP 한 행의 PSUM이 생성된다. 이렇듯 1차원 컨볼루션을 PE에 맵핑함으로써 PE 내부에 WGT, IFMP 한 행을 저장할 수 있다.

<p align="center"> <img src= "/assets/img/eyeriss/f4.png"> </p>
<div align="center"> Figure 04 </div>
<br/>

1차원 컨볼루션 연산의 결과 OFMP 한  행의 PSUM이 생성된다. 즉, 행의 부분합이지 완전하 행이 아니다. 그 이유는 다음과 같다. 첫번째, 컨볼루션 윈도우 (convolution window) 내의 모든 픽셀에 대해 Multiplication and Accumulation (MAC) 연산이 수행되어야 하는데, 현재는 컨볼루션 윈도우 내에서의 한 행에 대해 MAC 연산이 수행되었다. 따라서, 다른 컨볼루션 윈도우 내의 나머지 행에 대해서도 MAC 연산을 수행한 후 결과를 누적시켜야 한다. 두번째, IFMP와 WGT의 모든 채널에 대해 연산해야 한다. 따라서, 완전한 OFMP의 한 행을 생성하기 위해 PSUM 또한 PE 내부에 저장되어야 하고, 결과적으로 RS 데이터플로우는 모든 종류의 데이터를 PE 내부에 저장하여 재사용할 수 있다.

### 2-D Covnolution PE Set

1-D Convolution primitive in a PE 섹션에서 하나의 PE는 한 출력 채널에 대한 OFMP의 한 행의 PSUM을 생성함을 언급했다. 1차원 컨볼루션 혹은 하나의 PE를 일종의 블록으로 간주하고, 이 블록을 연결하여 전체 컨볼루션 연산을 수행하도록 설계할 수 있다. 그 처음은 여러 개의 PE를 묶어 한 세트로 만드는 것이다. 한 출력 채널에 대한 그리고 하나의 채널에 대한 완전한 OFMP를 계산하기 위해서는 하나의 컨볼루션 윈도우 내의 다른 행 또한 계산해야 하고, 모든 컨볼루션 윈도우를 계산해야 한다. 즉, 여러 개의 1차원 컨볼루션을 PE에 맵핑해야 함을 직관적으로 알 수 있다. 이때, 각 1차원 컨볼루션은 서로 독립적인 데이터에 대해 수행되므로 병렬적으로 처리할 수 있다. 이에, Eyeriss는 여러 PE를 묶어 2차원 컨볼루션 PE 세트를 정의한다.

한편, RS는 데이터의 열을 저장하는 것을 말한다. 어떤 데이터의 열을 어느 PE에 저장할 것인지, 저장하지 않은 데이터의 경우 어떤 방식으로 PE에 할당할 것인지에 따라 다양한 데이터플로우가 존재할 수 있다. 즉, RS 기반의 다양한 데이터플로우가 존재한다. Eyeriss의 경우 Figure 05와 같이 각 데이터의 행을 PE에 할당한다. WFT는 PE 세트 내에서 수형 방향으로 이동하고, IFMP는 대각 방향으로 이동한다. PE 세트의 한 열에 속한 각 PE는 OFMP의 한 행의 PSUM을 계산한다. 따라서 한 열 내의 각 PE에서 생성된 PSUM이 수직 방향으로 이동하며 누적된다. 결과적으로 PE 세트는 한 채널에 대한 OFMP를 생성한다.

<p align="center"> <img src= "/assets/img/eyeriss/f5.png"> </p>
<div align="center"> Figure 05 </div>
<br/>

Eyeriss가 설계한 데이터플로우의 장점은 모든 종류의 데이터를 재사용한다는 것이다. 컨볼루션 연산은 슬라이딩 매커니즘으로 동작하기에 공유되는 데이터가 존재한다. 또한, PE 세트의 한 열에 속한 각 PE는 OFMP의 한 행의 PSUM을 생성한다. 이에 따라 WGT와 IFMP, PSUM을 각각 수평과 대각, 수직 방향으로 이동시킴으로써 재사용할 수 있다. 좀 더 자세히 설명하면, 한 1차원 컨볼루션 연산에 사용된 WGT와 IFMP를 다른 1차원 컨볼루션 연산을 수행하는 PE에 포워딩시킴으로써 해당 데이터를 다시 메모리에서 가져오지 않아도 된다. PSUM의 경우 메모리에 저장되었다가 다시 가져와 누적하지 않아도 된다. 즉, 메모리에 대한 접근을 줄일 수 있다.

### Dimensions Beyond 2-D in PE Array

2-D Convolution PE set 섹션에서 PE 세트를 통해 하나의 그리고 한 채널의 IFMP와 WGT를 연산하여 한 출력 채널의 OFMP의 PSUM을 생성했다. 이를 Figure의 7중 루프 관점에서 보면, 빨간색 상자에 포함된 차원이 동시에 계산된다고 볼 수 있다. 왜냐하면, PE 세트 내의 각 열은 하나의 출력 채널에 대한 그리고 하나의 채널에 대한 OFMP의 각 행을 동시에 계산하고, 한 열 내의 각 PE는 OFMP의 한 행의 PSUM을 동시에 계산하기 때문이다. 하지만, 컨볼루션 레이어를 완전히 처리하기 위해서는 파란색 상자 내의 차원에 대한 계산도 고려해야 한다.

<p align="center"> <img src= "/assets/img/eyeriss/f6.png"> </p>
<div align="center"> Figure 06 </div>
<br/>

파란색 상자를 처리하는 가장 쉬운 방법으로 루프 순서대로 데이터를 스트리밍하는 것이 있을 수 있다. 예를 들어 1번 IFMP의 1번 채널과 1번 WGT의 1번 채널을 PE에 할당하여 1번 채널에 대한 OFMP의 PSUM을 계산한다. 이후, 1번 IFMP의 2번 채널과 1번 WGT의 2번 채널을 PE에 할당하여 PSUM을 계산한 후 이전의 1번 채널에 대한 PSUM과 누적시키는 방법이다.

하지만, 해당 방식으로 데이터를 할당하는 것은 에너지 효율을 최대화하려는 관점에서 고려해볼 부분이 있다 . 우선, 하나의 IFMP는 Figure 07와 같이 &C_{o}$개의 (현재의 경우 $C_{o}$가 2개) WGT에 대해 계산된다. 따라서, Figure 08과 같이 오직 한 개의 WGT만을 저장해 계산하는 것이 아닌 여러 개의 WGT를 합쳐서 저장한 후 계산할 수 있다. 이를 통해 IFMP를 모든 WGT에 대해 재사용할 수 있다.

<p align="center"> <img src= "/assets/img/eyeriss/f7.png"> </p>
<div align="center"> Figure 07 </div>
<br/>

<p align="center"> <img src= "/assets/img/eyeriss/f8.png"> </p>
<div align="center"> Figure 08 </div>
<br/>

또한, Figure 09와 같이 $C_{i}$개의 (현재의 경우 $C_{i}$가 2개) 채널에 대해 하나의 완전한 OFMP의 행을 계산하기 위해서는 모든 채널에 대해 OFMP의 행의 PSUM을 계산할 후 누적해야 한다. 따라서, Figure 10과 같이 오직 한 채널에 대한 IFMP와 WGT의 행을 저장해 계산하는 것이 아닌 여러 채널의 (예시에서는 2개) IFMP와 WGT의 행을 합쳐서 저장한 후에 계산할 수 있다. 이를 통해 PSUM의 이동을 최소화할 수 있다. Eyeriss는 앞서 언급한 2가지 경우를 모두 조합하여 활용한다. 즉, 하나의 PE내에 여러 개 그리고 여러 채널의 WGT가 저장되고, 여러 채널의 IFMP가 저장된다. 이에 하나의 PE는 여러 개의 1차원 컨볼루션 연산을 수행한다. 

<p align="center"> <img src= "/assets/img/eyeriss/f9.png"> </p>
<div align="center"> Figure 09 </div>
<br/>

<p align="center"> <img src= "/assets/img/eyeriss/f10.png"> </p>
<div align="center"> Figure 10 </div>
<br/>